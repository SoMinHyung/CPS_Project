{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "\"\"\"\n",
    "이 크롤러 클래스의 목적\n",
    "\n",
    "\n",
    "해외 영화 리뷰 사이트인 IMDB에서 \n",
    "\n",
    "1. 영화를 리뷰많은 순으로 정렬 (num개) #내가 설정한 num은 250\n",
    "2. 각 영화마다 평점10점 리뷰 50개, 평점 1점 리뷰 50개씩을 크롤링\n",
    "3. 긍정표현 12500개, 부정표현 12500개를 수집\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Scraper():    \n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"크롤링 시작\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def make_csv(self):\n",
    "        #처음에 실행할 때는 w로 실행하여, 기존의 데이터가 있으면 초기화\n",
    "        file = open(\"review.csv\", \"w\", newline = \"\", encoding  = 'UTF-8')\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow([\"review\",\"sentiment\"])\n",
    "        file.close()\n",
    "   \n",
    "\n",
    "\n",
    "    #CSV파일로 저장합니다. UTF-8을 사용하면, 한글이 깨지기때문에, euc-kr형식으로 저장합니다.\n",
    "    def write_csv(self, review, sentiment):\n",
    "        #파일은 데이터 추가, newline 시 공백 추가\n",
    "        file = open(\"review.csv\", \"a\", newline=\"\", encoding  = 'UTF-8')\n",
    "\n",
    "        wr = csv.writer(file)\n",
    "\n",
    "        for i in range(len(review)):\n",
    "            wr.writerow([review[i], sentiment[i]])\n",
    "\n",
    "        file.close()\n",
    "        \n",
    "    \n",
    "\n",
    "    def find_review_page(self,driver, num, title):\n",
    "        \"\"\"\n",
    "        num번째 영화의 리뷰페이지로 이동하는 함수입니다.\n",
    "        \"\"\"\n",
    "        #해당 영화 페이지로 이동\n",
    "        print(title)\n",
    "        driver.find_element_by_link_text(title).click()\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        #영화 페이지에서 리뷰페이지로 이동\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, \"html.parser\") \n",
    "        move = bs.find(\"div\", class_=\"user-comments\").find_all('a')\n",
    "        driver.find_element_by_link_text(move[-1].string).click()\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        \n",
    "\n",
    "    def review_scrap(self, driver, score):\n",
    "        \"\"\"\n",
    "        페이지 이동을 모두 마친 후, 영화 리뷰 페이지에서 크롤링하는 함수입니다\n",
    "        score = 1 이면 별점1점인 부정적인 리뷰\n",
    "        score = 10 이면 별점10점임 긍정적인 리뷰\n",
    "        \"\"\"\n",
    "        driver.implicitly_wait(3)\n",
    "        \n",
    "        #별점 1점을 선택\n",
    "        if score == 1:\n",
    "            driver.find_element_by_xpath('//*[@id=\"main\"]/section/div[2]/div[1]/form/div/div[3]/select/option[2]').click()\n",
    "            driver.implicitly_wait(3)\n",
    "        elif score == 10:\n",
    "            driver.find_element_by_xpath('//*[@id=\"main\"]/section/div[2]/div[1]/form/div/div[3]/select/option[11]').click()\n",
    "            driver.implicitly_wait(3)\n",
    "\n",
    "        #기본리뷰가 25개밖에 안되기 때문에 25개를 더 보기 누름\n",
    "        driver.find_element_by_id(\"load-more-trigger\").click()\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html, \"html.parser\") \n",
    "        reviews = bs.find(\"div\", class_=\"lister-list\").find_all(\"div\", class_=\"text show-more__control clickable\")\n",
    "        reviews2 = bs.find(\"div\", class_=\"lister-list\").find_all(\"div\", class_=\"text show-more__control\")\n",
    "\n",
    "        reviewList = []\n",
    "        sentimentList = []\n",
    "\n",
    "        for rev in reviews:\n",
    "            reviewList.append(rev.text)\n",
    "            if score == 1:\n",
    "                sentimentList.append(\"negative\")\n",
    "            else:\n",
    "                sentimentList.append(\"positive\")\n",
    "\n",
    "        for rev in reviews2:\n",
    "            reviewList.append(rev.text)\n",
    "            if score == 1:\n",
    "                sentimentList.append(\"negative\")\n",
    "            else:\n",
    "                sentimentList.append(\"positive\")\n",
    "\n",
    "        self.write_csv(reviewList, sentimentList)\n",
    "\n",
    "        \n",
    "        \n",
    "    def scrap(self, num):\n",
    "        path = os.getcwd()+\"\\chromedriver.exe\"\n",
    "        driver = webdriver.Chrome(path)\n",
    "        \n",
    "        try:\n",
    "            self.make_csv()\n",
    "\n",
    "            #평가가 많은 순으로 100개 정렬\n",
    "            driver.get(\"https://www.imdb.com/chart/top/?sort=nv,desc&mode=simple&page=1\")\n",
    "            driver.implicitly_wait(3)\n",
    "\n",
    "            #검색할 검색어는 1~100위의 영화\n",
    "            html = driver.page_source\n",
    "            bs = BeautifulSoup(html, \"html.parser\")\n",
    "            contents = bs.find(\"tbody\", class_=\"lister-list\").find_all(\"td\", class_=\"titleColumn\")\n",
    "\n",
    "            title = []\n",
    "\n",
    "\n",
    "            #전체 페이지에 250개의 영화가 있기때문에 num개만 추출하도록 설정\n",
    "            count = 0\n",
    "            for c in contents:\n",
    "                if count > num-1 :\n",
    "                    break\n",
    "                count += 1\n",
    "\n",
    "                title.append(c.find(\"a\").text)\n",
    "\n",
    "\n",
    "            count = 0\n",
    "            for t in title:\n",
    "                #n번째 영화의 리뷰페이지로 이동\n",
    "                self.find_review_page(driver, count, t)\n",
    "\n",
    "                #리뷰페이지에서 리뷰를 크롤링, csv파일에 저장\n",
    "                self.review_scrap(driver, 1)\n",
    "                self.review_scrap(driver, 10)\n",
    "\n",
    "                #크롤링을 마친 후, 초기 페이지로 이동\n",
    "                driver.get(\"https://www.imdb.com/chart/top/?sort=nv,desc&mode=simple&page=1\")\n",
    "                driver.implicitly_wait(3)\n",
    "\n",
    "                count += 1\n",
    "                print(str(count) + \"번 째 데이터 크롤링 완료\")\n",
    "\n",
    "            driver.implicitly_wait(4)\n",
    "            print(\"크롤링 종료\")\n",
    "\n",
    "\n",
    "        finally:\n",
    "            time.sleep(3)\n",
    "            driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
